// ⚠️ This file is auto-generated by wall-e (https://github.com/1712n/wall-e/).
// Do not edit it directly — instead, update the associated test/index.spec.* file and regenerate the code.

import { Client } from "pg";

interface Env {
  AI: {
    run: (
      model: string,
      inputs: { text: string[] },
    ) => Promise<{ data: number[][] }>;
  };
  HYPERDRIVE: { connectionString: string };
  DEDUP_AUTH_TOKEN: string;
}

interface Message {
  message_id: string;
  timestamp: string;
  content: string;
  platform_name?: string;
  platform_user_id?: string;
  platform_message_id?: string;
  platform_message_url?: string;
}

interface InputPayload {
  table_name: string;
  job_id: string;
  topic: string;
  industry: string;
  subindustry?: string;
  similarity_search_score_threshold: number;
  filter_by?: string[];
  messages: Message[];
}

interface NonDuplicateMessageInfo {
  message_id: string;
  content: string;
  similarity_search_score: number;
}

interface Stats {
  received: number;
  inserted: number;
  dropped: number;
  insertion_rate: number;
}

interface ResponseData {
  table_name: string;
  job_id: string;
  topic: string;
  industry: string;
  subindustry?: string;
  similarity_search_score_threshold: number;
  filter_by: string[];
  stats: Stats;
  non_duplicate_messages: NonDuplicateMessageInfo[];
}

const MODEL_NAME = "@cf/baai/bge-m3";
const TABLE_NAME_REGEX = /^[a-zA-Z_][a-zA-Z0-9_]*$/;

function buildFilterConditionsSql(
  filterByFields: string[],
  payload: InputPayload,
  queryParams: any[],
): string {
  const conditions: string[] = [];
  const filterSource: Record<string, string | undefined> = {
    job_id: payload.job_id,
    topic: payload.topic,
    industry: payload.industry,
    subindustry: payload.subindustry,
  };

  for (const field of filterByFields) {
    if (!Object.prototype.hasOwnProperty.call(filterSource, field)) {
      console.warn(
        `WARN: [QueryBuilder] Unknown field in filter_by: ${field} | JobID: ${payload.job_id}`,
      );
      continue;
    }
    const value = filterSource[field];
    if (value === undefined || value === null) {
      conditions.push(`${field} IS NULL`);
    } else {
      conditions.push(`${field} = $${queryParams.length + 1}`);
      queryParams.push(value);
    }
  }
  return conditions.length > 0 ? conditions.join(" AND ") : "TRUE";
}

export default {
  async fetch(request: Request, env: Env, _ctx: ExecutionContext): Promise {
    const rayIdForEarlyLog = request.headers.get("CF-Ray") || "unknown";

    if (request.method !== "POST") {
      console.log(
        `INFO: [Auth] MethodNotAllowed | RayID: ${rayIdForEarlyLog} | Method: ${request.method}`,
      );
      return new Response(
        JSON.stringify({
          status: "error",
          message: "Method not allowed. Use POST.",
        }),
        { status: 405, headers: { "Content-Type": "application/json" } },
      );
    }

    const authHeader = request.headers.get("Authorization");
    if (!authHeader || authHeader !== `Bearer ${env.DEDUP_AUTH_TOKEN}`) {
      console.log(`INFO: [Auth] AuthFailed | RayID: ${rayIdForEarlyLog}`);
      return new Response(
        JSON.stringify({ status: "error", message: "Authentication failed." }),
        { status: 401, headers: { "Content-Type": "application/json" } },
      );
    }

    let payload: InputPayload;
    try {
      payload = await request.json();
    } catch (e: any) {
      console.error(
        `ERROR: [InputParse] JSONParseFailed | RayID: ${rayIdForEarlyLog} | Details: ${e.message}`,
      );
      return new Response(
        JSON.stringify({
          status: "error",
          message: "Invalid JSON payload.",
          error: e.message,
        }),
        { status: 400, headers: { "Content-Type": "application/json" } },
      );
    }

    const job_id = payload.job_id || rayIdForEarlyLog;
    console.log(
      `INFO: [InputParse] PayloadReceived | JobID: ${job_id} | Messages: ${payload.messages?.length || 0}`,
    );

    const {
      table_name,
      topic,
      industry,
      subindustry,
      similarity_search_score_threshold,
      messages,
    } = payload;
    const filter_by = payload.filter_by || ["topic", "subindustry"];

    if (
      !table_name ||
      !payload.job_id ||
      !topic ||
      !industry ||
      similarity_search_score_threshold === undefined ||
      !messages
    ) {
      console.error(
        `ERROR: [InputValidation] MissingRequiredFields | JobID: ${job_id}`,
      );
      return new Response(
        JSON.stringify({
          status: "error",
          message:
            "Missing required fields: table_name, job_id, topic, industry, similarity_search_score_threshold, messages.",
        }),
        { status: 400, headers: { "Content-Type": "application/json" } },
      );
    }

    if (!TABLE_NAME_REGEX.test(table_name)) {
      console.error(
        `ERROR: [InputValidation] InvalidTableName | JobID: ${job_id} | TableName: ${table_name}`,
      );
      return new Response(
        JSON.stringify({
          status: "error",
          message: `Invalid table_name: ${table_name}. Must be alphanumeric/underscores, start with letter/underscore.`,
        }),
        { status: 400, headers: { "Content-Type": "application/json" } },
      );
    }

    const stats: Stats = {
      received: messages.length,
      inserted: 0,
      dropped: 0,
      insertion_rate: 0,
    };
    const non_duplicate_messages_output: NonDuplicateMessageInfo[] = [];

    const uniqueContentMessagesMap = new Map<string, Message>();
    for (const msg of messages) {
      if (
        msg.content === undefined ||
        msg.content === null ||
        typeof msg.content !== "string" ||
        msg.content.trim() === ""
      ) {
        console.warn(
          `WARN: [InputValidation] MsgContentInvalid | JobID: ${job_id} | MsgID: ${msg.message_id}`,
        );
        stats.dropped++;
        continue;
      }
      if (!uniqueContentMessagesMap.has(msg.content)) {
        uniqueContentMessagesMap.set(msg.content, msg);
      } else {
        stats.dropped++;
      }
    }

    const messagesToProcess = Array.from(uniqueContentMessagesMap.values());

    if (messagesToProcess.length === 0) {
      stats.insertion_rate = 0;
      const responseData: ResponseData = {
        table_name,
        job_id: payload.job_id,
        topic,
        industry,
        subindustry,
        similarity_search_score_threshold,
        filter_by,
        stats,
        non_duplicate_messages: [],
      };
      const reason =
        stats.received > 0
          ? "All messages were duplicates or invalid."
          : "No processable messages received.";
      console.log(
        `INFO: [ProcessingComplete] NoMessagesToProcess | JobID: ${job_id} | Reason: ${reason}`,
      );
      return new Response(
        JSON.stringify({
          status: "success",
          data: responseData,
          message: `Batch processing completed. ${reason}`,
        }),
        { status: 200, headers: { "Content-Type": "application/json" } },
      );
    }

    let pgClient: Client | null = null;
    try {
      pgClient = new Client({
        connectionString: env.HYPERDRIVE.connectionString,
      });
      await pgClient.connect();
      console.log(`INFO: [DBConnect] ConnectedToHyperdrive | JobID: ${job_id}`);

      for (const msg of messagesToProcess) {
        let embeddingVector: number[];
        try {
          const aiResponse = await env.AI.run(MODEL_NAME, {
            text: [msg.content],
          });
          if (
            !aiResponse.data ||
            !aiResponse.data[0] ||
            aiResponse.data[0].length === 0
          ) {
            throw new Error("AI response missing data or empty embedding");
          }
          embeddingVector = aiResponse.data[0];
        } catch (e: any) {
          console.error(
            `ERROR: [AIEmbedding] EmbeddingFailed | JobID: ${job_id} | MsgID: ${msg.message_id} | Details: ${e.message}`,
          );
          stats.dropped++;
          continue;
        }
        const formattedEmbedding = `[${embeddingVector.join(",")}]`;

        let current_similarity_score = 0.0;
        const similarityQueryParams: any[] = [formattedEmbedding];
        const filterClauseSql = buildFilterConditionsSql(
          filter_by,
          payload,
          similarityQueryParams,
        );

        const similarityQuery = `SELECT 1 - (embedding <=> $1::vector) AS similarity_score FROM ${table_name} WHERE ${filterClauseSql} ORDER BY embedding <=> $1::vector LIMIT 1;`;

        try {
          const similarityResult = await pgClient.query(
            similarityQuery,
            similarityQueryParams,
          );
          if (
            similarityResult.rows.length > 0 &&
            similarityResult.rows[0].similarity_score !== null
          ) {
            current_similarity_score = parseFloat(
              similarityResult.rows[0].similarity_score,
            );
          }
        } catch (e: any) {
          console.error(
            `ERROR: [DBSimilaritySearch] SearchFailed | JobID: ${job_id} | MsgID: ${msg.message_id} | Details: ${e.message}`,
          );
          stats.dropped++;
          continue;
        }

        if (current_similarity_score < similarity_search_score_threshold) {
          try {
            const insertQuery = `INSERT INTO ${table_name} (job_id, message_id, timestamp, topic, industry, subindustry, content, embedding, similarity_search_score, platform_name, platform_user_id, platform_message_id, platform_message_url) VALUES ($1, $2, $3, $4, $5, $6, $7, $8::vector, $9, $10, $11, $12, $13);`;
            const insertParams = [
              payload.job_id,
              msg.message_id,
              msg.timestamp,
              topic,
              industry,
              subindustry,
              msg.content,
              formattedEmbedding,
              current_similarity_score,
              msg.platform_name,
              msg.platform_user_id,
              msg.platform_message_id,
              msg.platform_message_url,
            ];
            await pgClient.query(insertQuery, insertParams);
            stats.inserted++;
            non_duplicate_messages_output.push({
              message_id: msg.message_id,
              content: msg.content,
              similarity_search_score: current_similarity_score,
            });
            console.log(
              `INFO: [DBInsert] MessageInserted | JobID: ${job_id} | MsgID: ${msg.message_id} | Score: ${current_similarity_score}`,
            );
          } catch (e: any) {
            console.error(
              `ERROR: [DBInsert] InsertFailed | JobID: ${job_id} | MsgID: ${msg.message_id} | Details: ${e.message}`,
            );
            stats.dropped++;
          }
        } else {
          stats.dropped++;
          console.log(
            `INFO: [Deduplication] MessageDropped | JobID: ${job_id} | MsgID: ${msg.message_id} | Score: ${current_similarity_score} | Threshold: ${similarity_search_score_threshold}`,
          );
        }
      }
    } catch (e: any) {
      console.error(
        `ERROR: [Processing] UnhandledError | JobID: ${job_id} | Details: ${e.message}`,
      );
      if (pgClient) {
        await pgClient
          .end()
          .catch((err) =>
            console.error(
              `ERROR: [DBClose] ClientCloseFailedOnError | JobID: ${job_id} | Details: ${err.message}`,
            ),
          );
      }
      return new Response(
        JSON.stringify({
          status: "error",
          message: "An error occurred during batch processing.",
          error: e.message,
        }),
        { status: 500, headers: { "Content-Type": "application/json" } },
      );
    } finally {
      if (pgClient) {
        await pgClient
          .end()
          .catch((err) =>
            console.error(
              `ERROR: [DBClose] ClientCloseFailedFinally | JobID: ${job_id} | Details: ${err.message}`,
            ),
          );
      }
    }

    stats.insertion_rate =
      stats.received > 0
        ? parseFloat((stats.inserted / stats.received).toFixed(4))
        : 0;

    const responseData: ResponseData = {
      table_name,
      job_id: payload.job_id,
      topic,
      industry,
      subindustry,
      similarity_search_score_threshold,
      filter_by,
      stats,
      non_duplicate_messages: non_duplicate_messages_output,
    };
    console.log(
      `INFO: [ProcessingComplete] BatchFinished | JobID: ${job_id} | Rcvd: ${stats.received} | Ins: ${stats.inserted} | Drpd: ${stats.dropped} | Rate: ${stats.insertion_rate}`,
    );
    return new Response(
      JSON.stringify({
        status: "success",
        data: responseData,
        message: "Batch processing completed successfully",
      }),
      { status: 200, headers: { "Content-Type": "application/json" } },
    );
  },
};
