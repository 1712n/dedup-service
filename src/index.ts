// ⚠️ This file is auto-generated by wall-e (https://github.com/1712n/wall-e/).
// Do not edit it directly — instead, update the associated test/index.spec.* file and regenerate the code.

import { Client } from "pg";

export interface Env {
  AI: {
    run: (modelName: string, inputs: any) => Promise;
  };
  HYPERDRIVE: {
    connectionString: string;
  };
  DEDUP_AUTH_TOKEN: string;
}

interface Message {
  message_id: string;
  timestamp: string;
  content: string;
  platform_name: string;
  platform_user_id: string;
  platform_message_id: string;
  platform_message_url: string;
}

interface RequestPayload {
  table_name: string;
  job_id: string;
  topic: string;
  industry: string;
  subindustry: string;
  similarity_search_score_threshold: number;
  filter_by?: string[];
  messages: Message[];
}

interface ResponseMessage {
  message_id: string;
  content: string;
}

interface ResponseStats {
  received: number;
  inserted: number;
  dropped: number;
  insertion_rate: number;
}

interface ResponsePayload {
  status: string;
  data: {
    table_name: string;
    job_id: string;
    topic: string;
    industry: string;
    subindustry: string;
    similarity_search_score_threshold: number;
    filter_by: string[];
    stats: ResponseStats;
    non_duplicate_messages: ResponseMessage[];
  };
  message: string;
}

export default {
  async fetch(request: Request, env: Env): Promise {
    try {
      console.log("INFO: Received request");

      if (request.method !== "POST") {
        console.log("INFO: Method not allowed");
        return new Response(
          JSON.stringify({
            status: "error",
            message: "Method not allowed",
          }),
          {
            status: 405,
            headers: { "Content-Type": "application/json" },
          },
        );
      }

      const authToken = request.headers.get("Authorization");
      if (
        !authToken ||
        !authToken.startsWith("Bearer ") ||
        authToken.slice(7) !== env.DEDUP_AUTH_TOKEN
      ) {
        console.log("INFO: Unauthorized request");
        return new Response(
          JSON.stringify({
            status: "error",
            message: "Unauthorized",
          }),
          {
            status: 401,
            headers: { "Content-Type": "application/json" },
          },
        );
      }

      const payload: RequestPayload = await request.json();
      console.log(
        `INFO: Processing ${payload.messages.length} messages for job ${payload.job_id}`,
      );

      const result = await processMessages(payload, env);

      console.log(
        `INFO: Completed processing. Inserted ${result.data.stats.inserted} messages`,
      );
      return new Response(JSON.stringify(result), {
        headers: { "Content-Type": "application/json" },
      });
    } catch (error) {
      console.error(`ERROR: Worker exception: ${error.message}`);
      return new Response(
        JSON.stringify({
          status: "error",
          message: "Internal server error",
        }),
        {
          status: 500,
          headers: { "Content-Type": "application/json" },
        },
      );
    }
  },
};

async function processMessages(payload: RequestPayload, env: Env): Promise {
  try {
    const filter_by = payload.filter_by || ["topic", "subindustry"];

    const stats: ResponseStats = {
      received: payload.messages.length,
      inserted: 0,
      dropped: 0,
      insertion_rate: 0,
    };

    const nonDuplicateMessages: ResponseMessage[] = [];

    console.log("INFO: Removing exact duplicates");
    const uniqueMessages = removeDuplicatesByContent(payload.messages);
    stats.dropped = stats.received - uniqueMessages.length;
    console.log(
      `INFO: Removed ${stats.dropped} exact duplicates, ${uniqueMessages.length} unique messages remain`,
    );

    console.log("INFO: Connecting to database");
    const dbClient = new Client({
      connectionString: env.HYPERDRIVE.connectionString,
    });
    await dbClient.connect();

    try {
      console.log("INFO: Starting sequential message processing");
      const insertedMessages = await processMessagesSequentially(
        uniqueMessages,
        payload,
        filter_by,
        dbClient,
        env,
      );

      stats.inserted = insertedMessages.length;
      stats.dropped += uniqueMessages.length - insertedMessages.length;
      stats.insertion_rate =
        stats.received > 0 ? stats.inserted / stats.received : 0;

      insertedMessages.forEach((msg) => {
        nonDuplicateMessages.push({
          message_id: msg.message_id,
          content: msg.content,
        });
      });

      console.log(
        `INFO: Completed processing. Inserted ${stats.inserted} messages, dropped ${stats.dropped} messages`,
      );
    } finally {
      await dbClient.end();
    }

    const response: ResponsePayload = {
      status: "success",
      data: {
        table_name: payload.table_name,
        job_id: payload.job_id,
        topic: payload.topic,
        industry: payload.industry,
        subindustry: payload.subindustry,
        similarity_search_score_threshold:
          payload.similarity_search_score_threshold,
        filter_by: filter_by,
        stats: stats,
        non_duplicate_messages: nonDuplicateMessages,
      },
      message: "Batch processing completed successfully",
    };

    return response;
  } catch (error) {
    console.error(`ERROR: Failed to process messages: ${error.message}`);
    throw error;
  }
}

function removeDuplicatesByContent(messages: Message[]): Message[] {
  try {
    const uniqueContents = new Set();
    return messages.filter((message) => {
      if (uniqueContents.has(message.content)) {
        return false;
      }
      uniqueContents.add(message.content);
      return true;
    });
  } catch (error) {
    console.error(`ERROR: Failed to remove duplicates: ${error.message}`);
    throw error;
  }
}

async function processMessagesSequentially(
  messages: Message[],
  payload: RequestPayload,
  filter_by: string[],
  dbClient: Client,
  env: Env,
): Promise<Message[]> {
  try {
    const insertedMessages: Message[] = [];
    const batchSize = 100;

    for (let i = 0; i < messages.length; i += batchSize) {
      const batch = messages.slice(i, i + batchSize);
      console.log(
        `INFO: Processing batch ${Math.floor(i / batchSize) + 1} of ${Math.ceil(messages.length / batchSize)}`,
      );

      const batchTexts = batch.map((msg) => msg.content);
      const embeddings = await generateEmbeddings(batchTexts, env);

      for (let j = 0; j < batch.length; j++) {
        const message = batch[j];
        const embedding = embeddings[j];

        try {
          const similarityScore = await checkSimilarity(
            embedding,
            payload,
            filter_by,
            dbClient,
          );

          if (similarityScore < payload.similarity_search_score_threshold) {
            await insertMessage(
              message,
              embedding,
              similarityScore,
              payload,
              dbClient,
            );

            insertedMessages.push(message);
            console.log(
              `INFO: Inserted message ${message.message_id} with similarity score ${similarityScore}`,
            );
          } else {
            console.log(
              `INFO: Dropped near-duplicate message ${message.message_id} with similarity score ${similarityScore}`,
            );
          }
        } catch (error) {
          console.error(
            `ERROR: Failed to process message ${message.message_id}: ${error.message}`,
          );
        }
      }
    }

    return insertedMessages;
  } catch (error) {
    console.error(
      `ERROR: Failed to process messages sequentially: ${error.message}`,
    );
    throw error;
  }
}

async function generateEmbeddings(
  texts: string[],
  env: Env,
): Promise<number[][]> {
  try {
    const modelName = "@cf/baai/bge-base-en-v1.5";
    console.log(`INFO: Generating embeddings for ${texts.length} texts`);

    const resp = await env.AI.run(modelName, { text: texts });
    return resp.data;
  } catch (error) {
    console.error(`ERROR: Failed to generate embeddings: ${error.message}`);
    throw new Error(`Failed to generate embeddings: ${error.message}`);
  }
}

async function checkSimilarity(
  embedding: number[],
  payload: RequestPayload,
  filter_by: string[],
  dbClient: Client,
): Promise {
  try {
    const filterParams: any[] = [];
    const filterConditions = filter_by
      .map((field) => {
        if (field === "topic") {
          filterParams.push(payload.topic);
          return `topic = $${filterParams.length}`;
        }
        if (field === "industry") {
          filterParams.push(payload.industry);
          return `industry = $${filterParams.length}`;
        }
        if (field === "subindustry") {
          filterParams.push(payload.subindustry);
          return `subindustry = $${filterParams.length}`;
        }
        if (field === "job_id") {
          filterParams.push(payload.job_id);
          return `job_id = $${filterParams.length}`;
        }
        return "";
      })
      .filter((cond) => cond !== "")
      .join(" AND ");

    if (!filterConditions) {
      return 0;
    }

    const formattedEmbedding = `[${embedding.join(",")}]`;
    filterParams.push(formattedEmbedding);

    const query = `
      SELECT 1 - (embedding <=> $${filterParams.length}::vector) as similarity_score
      FROM ${payload.table_name}
      WHERE ${filterConditions}
      ORDER BY embedding <=> $${filterParams.length}::vector
      LIMIT 1;
    `;

    const result = await dbClient.query(query, filterParams);

    if (result.rows.length === 0) {
      return 0;
    }

    return result.rows[0].similarity_score;
  } catch (error) {
    console.error(`ERROR: Failed to check similarity: ${error.message}`);
    throw new Error(`Failed to check similarity: ${error.message}`);
  }
}

async function insertMessage(
  message: Message,
  embedding: number[],
  similarityScore: number,
  payload: RequestPayload,
  dbClient: Client,
): Promise {
  try {
    const formattedEmbedding = `[${embedding.join(",")}]`;

    const query = `
      INSERT INTO ${payload.table_name} 
      (job_id, message_id, timestamp, topic, industry, subindustry, content, 
       embedding, similarity_search_score, platform_name, platform_user_id, 
       platform_message_id, platform_message_url)
      VALUES ($1, $2, $3, $4, $5, $6, $7, $8, $9, $10, $11, $12, $13)
    `;

    await dbClient.query(query, [
      payload.job_id,
      message.message_id,
      message.timestamp,
      payload.topic,
      payload.industry,
      payload.subindustry,
      message.content,
      formattedEmbedding,
      similarityScore,
      message.platform_name,
      message.platform_user_id,
      message.platform_message_id,
      message.platform_message_url,
    ]);
  } catch (error) {
    console.error(
      `ERROR: Failed to insert message ${message.message_id}: ${error.message}`,
    );
    throw new Error(`Failed to insert message: ${error.message}`);
  }
}
