// ⚠️ This file is auto-generated by wall-e (https://github.com/1712n/wall-e/).
// Do not edit it directly — instead, update the associated test/index.spec.* file and regenerate the code.

import { Client } from "pg";
type Env = { AI: any; HYPERDRIVE: any; DEDUP_AUTH_TOKEN: string };
type Msg = {
  message_id: string;
  timestamp?: string;
  content: string;
  platform_name?: string;
  platform_user_id?: string;
  platform_message_id?: string;
  platform_message_url?: string;
};
const MODEL = "@cf/baai/bge-m3";
const EMB_BATCH = 100;
export default {
  async fetch(req: Request, env: Env): Promise {
    const start = Date.now();
    try {
      if (req.method !== "POST") return resp(405, "Only POST allowed");
      const auth = req.headers.get("Authorization")?.replace(/^Bearer\s+/, "");
      if (auth !== env.DEDUP_AUTH_TOKEN) return resp(401, "Unauthorized");
      let body: any;
      try {
        body = await req.json();
      } catch (e) {
        return resp(400, "Invalid JSON");
      }
      const {
        table_name,
        job_id,
        topic,
        industry,
        subindustry,
        similarity_search_score_threshold: thr,
        messages,
      } = body;
      if (!table_name || !messages || !Array.isArray(messages) || !thr)
        return resp(400, "Missing fields");
      if (!/^[a-zA-Z0-9_]+$/.test(table_name))
        return resp(400, "Invalid table_name");
      const filter_by: Array = body.filter_by ?? ["topic", "subindustry"];
      const client = new Client({
        connectionString: env.HYPERDRIVE.connectionString,
      });
      await client.connect();
      const stats = {
        received: messages.length,
        inserted: 0,
        dropped: 0,
        insertion_rate: 0,
      };
      const non_duplicate_messages: Array<{
        message_id: string;
        content: string;
      }> = [];
      const seen = new Set();
      const uniqueMsgs: Msg[] = messages.filter((m) => {
        if (!m?.content) return false;
        if (seen.has(m.content)) {
          stats.dropped++;
          return false;
        }
        seen.add(m.content);
        return true;
      });
      const embeddings = await embed(
        uniqueMsgs.map((m) => m.content),
        env,
      );
      for (let i = 0; i < uniqueMsgs.length; i++) {
        const msg = uniqueMsgs[i];
        const embArr = embeddings[i];
        const embStr = "[" + embArr.join(",") + "]";
        const sim = await topSim(client, table_name, embStr, filter_by, {
          job_id,
          topic,
          industry,
          subindustry,
        });
        if (sim >= thr) {
          stats.dropped++;
          continue;
        }
        try {
          await client.query(
            `INSERT INTO ${table_name}(job_id,message_id,timestamp,topic,industry,subindustry,content,embedding,similarity_search_score,platform_name,platform_user_id,platform_message_id,platform_message_url)
       VALUES($1,$2,COALESCE($3,NOW()),$4,$5,$6,$7,$8::vector,$9,$10,$11,$12,$13)`,
            [
              job_id,
              msg.message_id,
              msg.timestamp,
              topic,
              industry,
              subindustry,
              msg.content,
              embStr,
              sim,
              msg.platform_name,
              msg.platform_user_id,
              msg.platform_message_id,
              msg.platform_message_url,
            ],
          );
          stats.inserted++;
          non_duplicate_messages.push({
            message_id: msg.message_id,
            content: msg.content,
          });
        } catch (e) {
          console.error("[ERROR] insert", e instanceof Error ? e.message : e);
        }
      }
      await client.end();
      stats.insertion_rate = stats.inserted / stats.received || 0;
      const res = {
        status: "success",
        data: {
          table_name,
          job_id,
          topic,
          industry,
          subindustry,
          similarity_search_score_threshold: thr,
          filter_by,
          stats,
          non_duplicate_messages,
        },
        message: "Batch processing completed successfully",
        duration_ms: Date.now() - start,
      };
      console.log("[INFO] done", res.data.stats);
      return new Response(JSON.stringify(res), {
        headers: { "Content-Type": "application/json" },
      });
    } catch (e) {
      console.error("[ERROR] fatal", e instanceof Error ? e.message : e);
      return resp(500, "Internal error");
    }
  },
};
async function embed(texts: string[], env: Env) {
  const out: number[][] = [];
  for (let i = 0; i < texts.length; i += EMB_BATCH) {
    const slice = texts.slice(i, i + EMB_BATCH);
    const r = await env.AI.run(MODEL, { text: slice });
    out.push(...r.data);
  }
  return out;
}
async function topSim(
  client: Client,
  table: string,
  embStr: string,
  filter_by: string[],
  vals: any,
): Promise {
  const params = [embStr];
  let where: string[] = [];
  filter_by.forEach((f) => {
    if (vals[f] !== undefined) {
      params.push(vals[f]);
      where.push(`${f}=$${params.length}`);
    }
  });
  const q = `SELECT 1-(embedding <=> $1::vector) sim FROM ${table} ${where.length ? "WHERE " + where.join(" AND ") : ""} ORDER BY sim DESC LIMIT 1`;
  try {
    const r = await client.query(q, params);
    return r.rows[0]?.sim ?? 0;
  } catch (e) {
    console.error("[ERROR] topsim", e instanceof Error ? e.message : e);
    return 0;
  }
}
function resp(code: number, msg: string) {
  return new Response(JSON.stringify({ status: "error", message: msg }), {
    status: code,
    headers: { "Content-Type": "application/json" },
  });
}
